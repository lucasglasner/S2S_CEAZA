{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import scipy.signal as signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_timeseries(ts, order, cutoff, btype='lowpass', fs=1, **kwargs):\n",
    "    \"\"\"Given an array, this function apply a butterworth (high/low pass) \n",
    "    filter of the given order and cutoff frequency.\n",
    "    For example:\n",
    "    If 'ts' is a timeseries of daily samples, filter_timeseries(ts,3,1/20)\n",
    "    will return the series without the 20 days or less variability using an\n",
    "    order 3 butterworth filter. \n",
    "    In the same way, filter_timeseries(ts,3,1/20, btype='highpass') will\n",
    "    return the series with only the 20 days or less variability.\n",
    "\n",
    "    Args:\n",
    "        ts (array_like): timeseries or 1D array to filter\n",
    "        order (int): _description_\n",
    "        cutoff (array_like): Single float for lowpass or highpass filters, \n",
    "        arraylike for bandpass filters.\n",
    "        btype (str, optional): The type of filter. Defaults to 'lowpass'.\n",
    "        fs (int): Sampling frequency. Defaults to 1\n",
    "        **kwargs are passed to scipy.signal.filtfilt\n",
    "\n",
    "    Returns:\n",
    "        output (array): Filtered array\n",
    "    \"\"\"\n",
    "    mask = np.isnan(ts)\n",
    "    nans = np.ones(len(ts))*np.nan\n",
    "    if mask.sum()==len(ts):\n",
    "        return nans\n",
    "    else:\n",
    "        b, a = signal.butter(order, cutoff, btype=btype, fs=fs)\n",
    "        filt=signal.filtfilt(b, a, ts[~mask], **kwargs)\n",
    "        output=np.ones(len(ts))*np.nan\n",
    "        output[np.where(~mask)] = filt\n",
    "        return output\n",
    "    \n",
    "def filter_xarray(data, dim, order, cutoff, btype='lowpass', parallel=False, fs=1):\n",
    "    \"\"\"Given a 3d DataArray, with time and spatial coordinates, this function apply\n",
    "    the 1D function filter_timeseries along the time dimension, filter the complete\n",
    "    xarray data.\n",
    "\n",
    "    Args:\n",
    "        data (XDataArray): data\n",
    "        dim (str): name of the time dimension\n",
    "        order (int): butterworth filter order\n",
    "        cutoff (array_like): if float, the cutoff frequency, if array must be the\n",
    "                            [min,max] frequencys for the bandpass filter.\n",
    "        btype (str, optional): {lowpass,highpass,bandpass}. Defaults to 'lowpass'.\n",
    "        parallel (bool, optional): If parallelize with dask. Defaults to False.\n",
    "        fs (int, optional): Sampling frequency. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        XDataArray: filtered data\n",
    "    \"\"\"\n",
    "    if parallel:\n",
    "        dask='parallelized'\n",
    "    else:\n",
    "        dask='forbidden'\n",
    "    filt = xr.apply_ufunc(filter_timeseries, data, order, cutoff, btype, fs,\n",
    "                          input_core_dims=[[dim],[],[],[],[]],\n",
    "                          output_core_dims=[[dim]],\n",
    "                          exclude_dims=set((dim,)),\n",
    "                          keep_attrs=True,\n",
    "                          vectorize=True, dask=dask)\n",
    "    filt[dim] = data[dim]\n",
    "    return filt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tropical_glorys_clim       = xr.open_dataset('data/GLORYS12V1/HOVMOLLERS/CLIMATOLOGY/glorys_tropical.nc')\n",
    "coastnorth_glorys_clim     = xr.open_dataset('data/GLORYS12V1/HOVMOLLERS/CLIMATOLOGY/glorys_coastnorth.nc')\n",
    "coastsouth_glorys_clim     = xr.open_dataset('data/GLORYS12V1/HOVMOLLERS/CLIMATOLOGY/glorys_coastsouth.nc')\n",
    "\n",
    "tropical_reforecast_clim   = xr.open_dataset('data/S2S/CLIMATOLOGY/reforecasts_tropical_clim.nc')\n",
    "coastnorth_reforecast_clim = xr.open_dataset('data/S2S/CLIMATOLOGY/reforecasts_coastnorth_clim.nc')\n",
    "coastsouth_reforecast_clim = xr.open_dataset('data/S2S/CLIMATOLOGY/reforecasts_coastsouth_clim.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tropical_glorys       = xr.open_dataset('data/GLORYS12V1/HOVMOLLERS/glorys_tropical.nc').convert_calendar('noleap', dim='time')\n",
    "tropical_reforecast   = xr.open_dataset('data/S2S/HOVMOLLERS/reforecasts_tropical.nc').convert_calendar('noleap', dim='inittime')\n",
    "\n",
    "coastnorth_glorys     = xr.open_dataset('data/GLORYS12V1/HOVMOLLERS/glorys_coastnorth.nc').convert_calendar('noleap', dim='time')\n",
    "coastnorth_reforecast = xr.open_dataset('data/S2S/HOVMOLLERS/reforecasts_coastnorth.nc').convert_calendar('noleap', dim='inittime')\n",
    "\n",
    "coastsouth_glorys     = xr.open_dataset('data/GLORYS12V1/HOVMOLLERS/glorys_coastsouth.nc').convert_calendar('noleap', dim='time')\n",
    "coastsouth_reforecast = xr.open_dataset('data/S2S/HOVMOLLERS/reforecasts_coastsouth.nc').convert_calendar('noleap', dim='inittime')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### check forecast for some study cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north_glorys = xr.concat([tropical_glorys.zos.groupby('time.dayofyear')-tropical_glorys_clim.zos,\n",
    "                          coastnorth_glorys.zos.groupby('time.dayofyear')-coastnorth_glorys_clim.zos\n",
    "                         ],'index').convert_calendar('gregorian')\n",
    "\n",
    "south_glorys = xr.concat([tropical_glorys.zos.groupby('time.dayofyear')-tropical_glorys_clim.zos,\n",
    "                          coastsouth_glorys.zos.groupby('time.dayofyear')-coastsouth_glorys_clim.zos\n",
    "                         ],'index').convert_calendar('gregorian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north_reforecast = xr.concat([tropical_reforecast.zos.groupby('inittime.dayofyear')-tropical_reforecast_clim.zos,\n",
    "                          coastnorth_reforecast.zos.groupby('inittime.dayofyear')-coastnorth_reforecast_clim.zos\n",
    "                         ],'index').convert_calendar('gregorian', dim='inittime')\n",
    "\n",
    "south_reforecast = xr.concat([tropical_reforecast.zos.groupby('inittime.dayofyear')-tropical_reforecast_clim.zos,\n",
    "                          coastsouth_reforecast.zos.groupby('inittime.dayofyear')-coastsouth_reforecast_clim.zos\n",
    "                         ],'index').convert_calendar('gregorian', dim='inittime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itime = '2008-04-20'\n",
    "ftime = (pd.to_datetime(itime)+pd.Timedelta(days=46)).strftime('%F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsouth_reforecast.swap_dims({'index':'lat'}).sel(lat=-35,method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = south_glorys.sel(index=1133)\n",
    "p1['time'] = p1.time-pd.Timedelta(hours=12)\n",
    "p2 = south_reforecast.sel(index=78).drop_duplicates('inittime')#.rename({'inittime':'time'})#.interp(inittime=p1.time.values)\n",
    "p3 = []\n",
    "for lead in p2.leadtime.values:\n",
    "    p = p2.sel(leadtime=lead)\n",
    "    p['inittime'] = p.inittime+pd.Timedelta(days=lead)\n",
    "    p = p.rename({'inittime':'time'})\n",
    "    p = p.interp(time=p1.time.values)\n",
    "    p = dict(p.convert_calendar('noleap').groupby('time.month'))\n",
    "    p3.append(p)\n",
    "\n",
    "\n",
    "p1 = dict(p1.convert_calendar('noleap').groupby('time.month'))\n",
    "\n",
    "corr = np.empty((12,46))\n",
    "for dayofyear in range(12):\n",
    "    for lead in range(46):\n",
    "        corr[dayofyear,lead] = xr.corr(p1[dayofyear+1],p3[lead][dayofyear+1],'time')\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.contourf(corr.T**2, vmin=0, vmax=1, cmap='nipy_spectral', levels=np.linspace(0,1,100))\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = south_glorys.sel(index=893)\n",
    "p1['time'] = p1.time-pd.Timedelta(hours=12)\n",
    "p2 = south_reforecast.sel(index=66).drop_duplicates('inittime')#.rename({'inittime':'time'})#.interp(inittime=p1.time.values)\n",
    "p3 = []\n",
    "for lead in p2.leadtime.values:\n",
    "    p = p2.sel(leadtime=lead)\n",
    "    p['inittime'] = p.inittime+pd.Timedelta(days=lead)\n",
    "    p = p.rename({'inittime':'time'})\n",
    "    p = p.interp(time=p1.time.values)\n",
    "    p = dict(p.convert_calendar('noleap').groupby('time.month'))\n",
    "    p3.append(p)\n",
    "\n",
    "\n",
    "p1 = dict(p1.convert_calendar('noleap').groupby('time.month'))\n",
    "\n",
    "corr = np.empty((12,46))\n",
    "for dayofyear in range(12):\n",
    "    for lead in range(46):\n",
    "        corr[dayofyear,lead] = xr.corr(p1[dayofyear+1],p3[lead][dayofyear+1],'time')\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.contourf(corr.T**2, vmin=0, vmax=1, cmap='nipy_spectral', levels=np.linspace(0,1,100))\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = south_glorys.sel(index=1073)\n",
    "p1['time'] = p1.time-pd.Timedelta(hours=12)\n",
    "p2 = south_reforecast.sel(index=77).drop_duplicates('inittime')#.rename({'inittime':'time'})#.interp(inittime=p1.time.values)\n",
    "p3 = []\n",
    "for lead in p2.leadtime.values:\n",
    "    p = p2.sel(leadtime=lead)\n",
    "    p['inittime'] = p.inittime+pd.Timedelta(days=lead)\n",
    "    p = p.rename({'inittime':'time'})\n",
    "    p = p.interp(time=p1.time.values)\n",
    "    p = dict(p.convert_calendar('noleap').groupby('time.month'))\n",
    "    p3.append(p)\n",
    "\n",
    "# del p, p2\n",
    "p1 = dict(p1.convert_calendar('noleap').groupby('time.month'))\n",
    "\n",
    "corr = np.empty((12,46))\n",
    "for dayofyear in range(12):\n",
    "    for lead in range(46):\n",
    "        corr[dayofyear,lead] = xr.corr(p1[dayofyear+1],p3[lead][dayofyear+1],'time')\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.contourf(corr.T**2, vmin=0, vmax=1, cmap='nipy_spectral', levels=np.linspace(0,1,100))\n",
    "plt.colorbar()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
